|    | LLM_Combo                                         |   Count_Lite |   AvgPrecision_Lite |   MaxPrecision_Lite |
|---:|:--------------------------------------------------|-------------:|--------------------:|--------------------:|
|  0 | Claude 4 Sonnet                                   |            2 |              58.5   |               60.33 |
|  1 | Claude 3.7 Sonnet+o4-mini                         |            1 |              60     |               60    |
|  2 | No Info                                           |            9 |              35.67  |               55    |
|  3 | Claude 3.7 Sonnet+Gemini 2.5 Pro                  |            1 |              51.67  |               51.67 |
|  4 | Claude 3.5 Haiku+Claude 3.5 Sonnet+Gemini 2.5 Pro |            1 |              49     |               49    |
|  5 | GPT-4                                             |            8 |              25.17  |               48.67 |
|  6 | Claude 3.5 Sonnet                                 |           17 |              41     |               48.33 |
|  7 | Claude 3.5 Sonnet+o3-mini+o4-mini                 |            1 |              48.33  |               48.33 |
|  8 | Claude 3.7 Sonnet                                 |            1 |              48     |               48    |
|  9 | Claude 3.5 Sonnet+DeepSeek R1                     |            1 |              47     |               47    |
| 10 | Claude 3.5 Sonnet+GPT-4o                          |            4 |              35     |               43    |
| 11 | Claude 3.5 Haiku+Claude 3.5 Sonnet                |            1 |              41.67  |               41.67 |
| 12 | GPT-4o                                            |           14 |              28.835 |               39.33 |
| 13 | Deepseek V3                                       |            2 |              33.685 |               36.67 |
| 14 | Claude 3.5 Sonnet+GPT-4                           |            1 |              33     |               33    |
| 15 | o3-mini                                           |            2 |              31.33  |               32.33 |
| 16 | Claude 3+GPT-4o                                   |            2 |              25.83  |               26.33 |
| 17 | Qwen2.5                                           |            3 |              23.33  |               24.67 |
| 18 | LLama 3+Mistral-Large+Qwen2.5+Granite             |            1 |              23.67  |               23.67 |
| 19 | GPT-4+GPT-4o                                      |            1 |              21.67  |               21.67 |
| 20 | Claude 3                                          |            2 |               8     |               11.67 |
| 21 | Claude 2                                          |            1 |               3     |                3    |
| 22 | LLama 3                                           |            2 |               1.165 |                1.33 |
| 23 | GPT3/3.5                                          |            1 |               0.33  |                0.33 |